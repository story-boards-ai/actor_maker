{
  "delayTime": 18214,
  "executionTime": 751662,
  "id": "5df96ab7-138e-4e49-b569-923286cdbf26-e1",
  "input": {
    "training_config": {
      "learning_rate": 0.0003,
      "max_train_steps": 1200,
      "mode": "custom-actors",
      "model_name": "actor_1_V1",
      "request_id": "1_1760623175837",
      "tenant_id": "actor_maker",
      "user_id": "actor_maker_user"
    },
    "training_data": {
      "s3_urls": [
        "s3://story-boards-assets/system_actors/training_data/0001_european_20_female/0001_european_20_female_8.png",
        "s3://story-boards-assets/system_actors/training_data/0001_european_20_female/0001_european_20_female_12.png",
        "s3://story-boards-assets/system_actors/training_data/0001_european_20_female/0001_european_20_female_14.png",
        "s3://story-boards-assets/system_actors/training_data/0001_european_20_female/0001_european_20_female_15.jpg",
        "s3://story-boards-assets/system_actors/training_data/0001_european_20_female/0001_european_20_female_16.jpg",
        "s3://story-boards-assets/system_actors/training_data/0001_european_20_female/0001_european_20_female_18.jpg",
        "s3://story-boards-assets/system_actors/training_data/0001_european_20_female/0001_european_20_female_19.jpg",
        "s3://story-boards-assets/system_actors/training_data/0001_european_20_female/0001_european_20_female_20.jpg",
        "s3://story-boards-assets/system_actors/training_data/0001_european_20_female/0001_european_20_female_23.jpg",
        "s3://story-boards-assets/system_actors/training_data/0001_european_20_female/0001_european_20_female_24.jpg",
        "s3://story-boards-assets/system_actors/training_data/0001_european_20_female/0001_european_20_female_26.jpg",
        "s3://story-boards-assets/system_actors/training_data/0001_european_20_female/0001_european_20_female_28.jpg"
      ]
    },
    "workflow": {
      "2": {
        "_meta": {
          "title": "FluxTrain ModelSelect"
        },
        "class_type": "FluxTrainModelSelect",
        "inputs": {
          "clip_l": "clip_l.safetensors",
          "t5": "t5xxl_fp8.safetensors",
          "transformer": "flux1-dev-fp8.safetensors",
          "vae": "ae.safetensors"
        }
      },
      "4": {
        "_meta": {
          "title": "Flux Train Loop"
        },
        "class_type": "FluxTrainLoop",
        "inputs": {
          "network_trainer": [
            "107",
            0
          ],
          "steps": 1200
        }
      },
      "14": {
        "_meta": {
          "title": "Flux Train Save LoRA"
        },
        "class_type": "FluxTrainSave",
        "inputs": {
          "copy_to_comfy_lora_folder": false,
          "network_trainer": [
            "4",
            0
          ],
          "save_state": false
        }
      },
      "37": {
        "_meta": {
          "title": "Flux Train Validation Settings"
        },
        "class_type": "FluxTrainValidationSettings",
        "inputs": {
          "base_shift": 0.5,
          "guidance_scale": 3,
          "height": 1024,
          "max_shift": 1.15,
          "seed": 42,
          "shift": true,
          "steps": 2,
          "width": 1024
        }
      },
      "88": {
        "_meta": {
          "title": "Number of epochs"
        },
        "class_type": "Display Any (rgthree)",
        "inputs": {
          "output": "",
          "source": [
            "107",
            1
          ]
        }
      },
      "95": {
        "_meta": {
          "title": "Optimizer Config"
        },
        "class_type": "OptimizerConfig",
        "inputs": {
          "extra_optimizer_args": "",
          "lr_scheduler": "constant",
          "lr_scheduler_num_cycles": 3,
          "lr_scheduler_power": 1,
          "lr_warmup_steps": 0,
          "max_grad_norm": 1,
          "min_snr_gamma": 5,
          "optimizer_type": "adamw8bit"
        }
      },
      "97": {
        "_meta": {
          "title": "Visualize Loss"
        },
        "class_type": "VisualizeLoss",
        "inputs": {
          "height": 512,
          "log_scale": false,
          "network_trainer": [
            "4",
            0
          ],
          "normalize_y": true,
          "plot_style": "seaborn-v0_8-dark-palette",
          "width": 768,
          "window_size": 100
        }
      },
      "98": {
        "_meta": {
          "title": "Save Image"
        },
        "class_type": "SaveImage",
        "inputs": {
          "filename_prefix": "flux_lora_loss_plot",
          "images": [
            "97",
            0
          ]
        }
      },
      "105": {
        "_meta": {
          "title": "Display Any (rgthree)"
        },
        "class_type": "Display Any (rgthree)",
        "inputs": {
          "output": "",
          "source": [
            "107",
            2
          ]
        }
      },
      "107": {
        "_meta": {
          "title": "Init Flux LoRA Training"
        },
        "class_type": "InitFluxLoRATraining",
        "inputs": {
          "T5_lr": 0,
          "additional_args": "",
          "apply_t5_attn_mask": true,
          "attention_mode": "sdpa",
          "blocks_to_swap": 0,
          "cache_latents": "memory",
          "cache_text_encoder_outputs": "memory",
          "clip_l_lr": 0,
          "dataset": [
            "109",
            0
          ],
          "discrete_flow_shift": 3.1582000000000003,
          "flux_models": [
            "2",
            0
          ],
          "fp8_base": true,
          "gradient_checkpointing": "enabled",
          "gradient_dtype": "bf16",
          "guidance_scale": 1,
          "highvram": true,
          "learning_rate": 0.0003,
          "logit_mean": 0,
          "logit_std": 1,
          "max_train_steps": 1200,
          "mode_scale": 1.29,
          "model_prediction_type": "raw",
          "network_alpha": 16,
          "network_dim": 16,
          "optimizer_settings": [
            "95",
            0
          ],
          "output_dir": "/model_output",
          "output_name": "flux_lora_file_name",
          "sample_prompts": [
            "146",
            0
          ],
          "save_dtype": "bf16",
          "sigmoid_scale": 1,
          "timestep_sampling": "shift",
          "train_text_encoder": "disabled",
          "weighting_scheme": "logit_normal"
        }
      },
      "108": {
        "_meta": {
          "title": "TrainDatasetGeneralConfig"
        },
        "class_type": "TrainDatasetGeneralConfig",
        "inputs": {
          "alpha_mask": false,
          "caption_dropout_rate": 0,
          "caption_extension": ".txt",
          "color_aug": false,
          "flip_aug": false,
          "reset_on_queue": false,
          "shuffle_caption": false
        }
      },
      "109": {
        "_meta": {
          "title": "Train 512x512 Dataset"
        },
        "class_type": "TrainDatasetAdd",
        "inputs": {
          "batch_size": 1,
          "bucket_no_upscale": false,
          "class_tokens": "0001_european_20_female",
          "dataset_config": [
            "108",
            0
          ],
          "dataset_path": "/training_data",
          "enable_bucket": true,
          "height": 512,
          "max_bucket_reso": 1024,
          "min_bucket_reso": 256,
          "num_repeats": 1,
          "width": 512
        }
      },
      "133": {
        "_meta": {
          "title": "Flux LoRA Train End"
        },
        "class_type": "FluxTrainEnd",
        "inputs": {
          "network_trainer": [
            "14",
            0
          ],
          "save_state": false
        }
      },
      "146": {
        "_meta": {
          "title": "Prompts for Validation"
        },
        "class_type": "StringConstantMultiline",
        "inputs": {
          "string": "portrait of a young woman, 0001_european_20_female|a young woman walking in New York at night, 0001_european_20_female|a woman wearing a colorful outfit on a tropical beach, 0001_european_20_female|portrait of a young woman wearing a leather jacket in New York at sunset, 0001_european_20_female",
          "strip_newlines": true
        }
      }
    }
  },
  "output": {
    "job_id": "1_1760623175837",
    "loraName": "actor_1_V1.safetensors",
    "loraUrl": "https://s3-accelerate.amazonaws.com/storyboard-user-files/actor_maker_user/custom-actors/models/actor_1_V1.safetensors",
    "message": "LoRA training completed successfully in 747.84 seconds",
    "model_info": {
      "download_url": "https://s3-accelerate.amazonaws.com/storyboard-user-files/actor_maker_user/custom-actors/models/actor_1_V1.safetensors",
      "file_extension": ".safetensors",
      "model_type": "lora",
      "name": "actor_1_V1.safetensors",
      "size_bytes": 153272040
    },
    "status": "success",
    "tenant_id": "actor_maker",
    "training_type": "character",
    "user_id": "actor_maker_user"
  },
  "status": "COMPLETED",
  "webhook": "https://cb5349cd8445.ngrok-free.app/api/training-webhook"
}