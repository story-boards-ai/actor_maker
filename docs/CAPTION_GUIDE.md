Full Clear Guide to Captioning for Flux / LoRA Style Training

1. Purpose of captions + trigger token

Your caption file (a .txt paired with each image) is how the model learns to link visual features to text tokens.

Put your trigger token (a unique, rarely used word or phrase) into every caption. This token is how you'll later call up the style in prompts.

The caption should describe non-style / non-fixed content (scene, subject, objects, pose, lighting) — anything you don’t want baked into the style permanently.

You should not describe the style itself (e.g. “oil painting style,” “vibrant color palette,” “soft brush strokes”) — those should be encoded implicitly by the LoRA via the trigger token, not repeated in every caption.

So the general structure is:

[Description of subject / scene / objects / mood etc.] + trigger_token

Examples:

“a foggy mountain valley with pine trees, winding river — mystyleX”

“portrait of a girl on a swing under blossoming cherry trees — mystyleX”

“an ancient stone bridge over a creek in twilight — mystyleX”

Keep it simple, descriptive, but style-neutral. The “style” is represented by mystyleX.

2. What to describe (and vary)

Include in your captions things that:

Change between images: backgrounds, lighting, weather, pose, objects, composition

Elements you may want to prompt on or out later (e.g. “smiling face,” “holding a sword,” “backlit,” “forest,” “city street”)

Details that help distinguish one image from another so the model doesn’t collapse all images into nearly identical embeddings

Vary your captions across images so the model doesn’t assume a fixed background or lighting.

3. What not to describe (or avoid)

Avoid or omit:

Descriptions of the style itself (brush strokes, pastel palette, ink lines, etc.) — this risks the LoRA learning the style in text-descriptive form rather than visual mapping

Overly elaborate or verbose aesthetic adjectives (unless you really need them in a prompt later)

Contradictory style descriptors across images (e.g. “gloomy” in one, “bright and cheerful” in another) unless you intend that variation

Redundant or irrelevant details that don’t help the model (e.g. “a small pebble at the bottom left corner”)

In short: don’t over-describe. Less is more when it comes to the style part.

4. Caption length, consistency, and format

Aim for one moderate-length sentence (roughly 8 to 20 words) describing the scene, then append the trigger token.

Be consistent in how you place the trigger token (e.g. always at the end, possibly preceded by “—” or “in the style of”) so the model learns the structure.

Some variation in phrasing is okay (natural language vs tag lists) to help generalization.

Avoid wildly variable caption lengths; keep them in a similar ballpark so the model doesn’t overweigh very long ones or ignore very short ones.

5. Practical tips & tradeoffs

Use a unique trigger token (that doesn’t clash with existing model vocabulary) to maximize clarity.

For style LoRA training (versus character / subject LoRA), many practitioners omit style descriptors entirely and rely purely on the trigger token + descriptive content.

If your style dataset is narrow (e.g. many images of the same kind of scene), the model may overfit — diversity helps.

After training, try prompting exactly your captions (with the trigger token) and also more generic prompts (with trigger token) to see if it generalizes or just memorizes.

Be prepared to experiment captioned vs non-captioned variants — some style LoRAs are trained with minimal captions (just trigger words) and still perform well.

Always manually review autogenerated captions (if using autoflag/tagger tools) to remove bad or conflicting phrasing.

What Online Resources Say (and where they differ)

Here are 5 resources that discuss captioning, along with how their advice aligns or conflicts:

Finetuners.ai — “Training LoRA on Flux: Best Practices & Settings”

They argue captions help Flux understand images and help prompting later.
finetuners.ai

They also say: for “single subject” style LoRAs you might skip captions—but they still lean toward using them.
finetuners.ai

Their example caption is rich in style descriptors (e.g. “vibrant, clean 3D style”) which conflicts somewhat with the caution to not over-describe style.

Fal / blog.fal.ai — “Training FLUX Style LoRA”

They strongly advocate associating style with a short trigger phrase, and writing captions that describe scene without style descriptors, then appending “in the style of trigger.”
blog.fal.ai

They explicitly say: “Instead of just txcl painting for caption, describe image + trigger phrase, but do not describe style in detail.”
blog.fal.ai

They also warn: overtraining may kill prompt flexibility.
blog.fal.ai

Pelayo Arbués — “What Exactly to Caption for Flux LoRA Training”

He advises: “caption elements you want to prompt in or out; anything else becomes part of the character/style implicitly.”
pelayoarbues.com

He remarks that variety (smile vs no smile, different gazes) helps flexibility.
pelayoarbues.com

He also notes that it's possible to train with no captions at all, but quality tends to suffer.
pelayoarbues.com

HuggingFace / alvdansen — “Enhancing LoRA Training Through Effective Captions”

They advise: don’t describe everything — only name elements not tied to the core concept you’re training.
huggingface.co

They also recommend mixing caption styles (narrative, list, simple) to improve learning.
huggingface.co

They caution against naming the style (e.g. “oil painting”) unless that's part of your target, because the base model already has many style biases.
huggingface.co

Reticulated — “Creating a Flux Dev LoRA”

They confirm that caption files must match images (same folder, same basename) and that trigger words are added in captions.
Reticulated

They suggest workflows to bulk caption images, incorporating trigger tokens
